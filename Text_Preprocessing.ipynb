{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ta269uec/nlppapers/blob/main/Text_Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "URaKK8Yd6hrW",
    "tags": []
   },
   "source": [
    "# Papers on Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Is preprocessing of text really worth your time for toxic comment classification?](https://arxiv.org/pdf/1806.02908.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authors study impact of text transformation for toxic comment datasets (Jigsaw) and conclude no  transformation produce relatively decent model and basic transformations, in some cases, lead to worse performance. \n",
    "\n",
    "\n",
    "\n",
    "Online comments data has non-standard English words full of typos and spurious characters. Multi-folds including originating from mobile devices, use of acronyms, leetspeak words (http://1337.me/), or intentionally obfuscating words (abusive) to avoid filters by inserting spurious characters, using phonemes, dropping characters etc. leading to feature explosion and difficulty training model.\n",
    "\n",
    "\n",
    "\n",
    "Bao et. al. used five transformations namely URLs features reservation, negation transformation, repeated letters normalization, stemming and lemmatization on twitter data and applied linear classifier and found the accuracy of the classification increases when URLs features reservation, negation transformation and repeated letters normalization are employed while decreases when stemming and lemmatization are applied [19]. \n",
    "\n",
    "\n",
    "\n",
    "Jianqiang and Xiaolin found removal of URLs, the removal of stop words and the removal of numbers have minimal effect on accuracy whereas replacing negation and expanding acronyms can improve the accuracy.\n",
    "\n",
    "\n",
    "\n",
    "Most of the authors used conventional ML models such as SVM, LR, RF and NB. We are expanding our candidate pool for transformations and using latest state-of-the-art models such as LR, NBSVM, XGBoost and Bidirectional LSTM model using fastTextâA˘ Zs skipgram ´ word vector.\n",
    "\n",
    "\n",
    "\n",
    "In this paper we have identified 20 different atomic transformations (plus 15 sequence of transformations) to preprocess the texts.\n",
    "\n",
    "\n",
    "\n",
    "1. Remove rare words: In the Jigsaw toxic text corpora, a staggering 65.3% of the words occurred just once and 88.3% of the words appeared five or less number of times (See Fig. 2(a)). This shows that there are many different ways to represent the same words. The Fig. 2(b) below shows different number of ways (that we could identify, actual number may be more) some of the abusive words are written in the Jigsaw corpora.\n",
    "\n",
    "2. Use regular expression for blacklisted words: A regular expression is created for each one of the blacklisted word and every word in corpora is compared to see which is matched. The âAŸ*â ˘ A˘ Z (asterisk) is assumed ´ to be the wild character that can match any character. Our algorithm knows that s**t, S***T, sh**, shi*, s*it:), SHYT, sHYt, shiiiit, shiiiiiiiiiiiit and siht, all represent the same word.\n",
    "\n",
    "\n",
    "\n",
    "3. Check if the words if they look like proper name: A large number of words with frequency less than 10 looked like proper names (person, city or other proper names). We matched each words with compiled list of 1) city names 2) countries 3) nationalities 4) ethnicities 5) names of persons (a. English names, b. Spanish names, c. Hindi first names, d. Hindi last names e. Muslim names). • Replace profane words using fuzzy matching: We used fuzzy matching to see how close a word is to the abusive words based on Levenshtein distance. By carefully selecting the threshold based on empirical value, the algorithm can detect that the words; SHUIT, SHYT, SHIZZ, SHiiT, SHITV, $h1+, $hit, 5h1t; represent the same word.\n",
    "\n",
    "\n",
    "\n",
    "4. Replace common words using fuzzy matching. In this transformation, we assumed that any word with a frequency of more than 100 (empirically chosen) is frequent word. Then we normalized these frequent words by removing all non-alphanumeric characters and resulted in 4,606 unique frequent words. Then, we fuzzy matched all the raw words in corpora with frequent word to get the closest word. A matching percent threshold matching_pct is used to decide if a word is a match with a frequent word )\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOE13zMEAKt8EHALxxXtiAH",
   "include_colab_link": true,
   "name": "Text Preprocessing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
